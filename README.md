!!! This README.md contains all of the markdown from GCN MISP. For matching code with annotations, please refer to 'GCN MISP.ipynb'
 
 # Solving Maximum Independent Set Problem w/ Graph Convolutional Neural Network

For this project, I will be using a Graph Convolutional Neural Network (GCN) to generate approximate solutions to the maximum independent set problem given a graph G. For the implementation, I will be using the [**PyTorch**](https://github.com/pytorch/pytorch) library as well as the [**NetworkX**](https://github.com/networkx/networkx) library for graph representation.

## Imports
The first step is to import the required modules needed for this implementation. If attempting to run this code on your own machine and run into "module not found" errors, you may need to run a `pip install` command for the specified libraries.

- `torch`provides framework for manipulating tensors and implementing machine learning algorithms
- `torch.nn.functional` provides additional functions for implementing neural network functions
- `torch.optim` provides various optimization algorithms
- `networkx`provides framework for generating and manipulating graph data
- `torch_geometric.nn.GCNConv` graph convolutional network convolution operator
- `networkx.algorithms.approximation`provides complete approximation algorithms

- `math` is used in generating the underlying graphs
- `matplotlib.pyplot` allows us to plot the graphs generated by NetworkX
- `numpy` is used to track the running time of algorithms
- `time` is used to track the running time of algorithms

## Creating Underlying Graph
I will now create the underlying graph to be used in the algorithm. To create the graph, I will be using the `nx.random_tree()` function which takes the following parameters:
- `n` [int] The number of nodes in the tree
- `seed` [integer, random_state, or None (default)] Indicator of random number generation state

I use a tree as a base for the graph to ensure that the graph is connected. If any nodes are not connected, then the fitness function will always be biased towards the unconnected nodes. After creating the base for the graph, I create a second graph using the `nx.gnm_random_graph()` function which takes in the following parameters:
- `n` [int] The number of nodes in the graph
- `m` [int] The number of edges
- `seed` [integer, random_state, or None (default)] Indicator of random number generation state
- `directed` [bool, optional (default=False)] If True return a directed graph

The edges from this graph are then added to the original tree to produce a deterministically random connected graph.

### Helper Function
The function `get_node_indexs` takes in a graph, **G** and an integer list representation of the provided maximum independent set **MIS** where each element in **MIS** represents the index of a node from **G** included in the set.

## Network Architecture
The next step is to define the network architecture. The class `GCN` inherits from the `torch.nn.Module` class and provides the foundation for the **graph convolutional network**. This GCN has two layers where the input to the network is a graph represented by `edge_index` and its node features `x`.

The output is a tensor of node-level predictions that have been passed through a sigmoid activation function.

### Hyper Parameters
The following section holds some of the hyper parameters required for running the algorithm.
- `num_epochs`: The number of epochs the training loop will run for
- `learning_rate`: The step size at each iteration while updating model
- `dropout`: probability of dropout used in model creation

## Wrapper for Running GCN
The below section runs the training loop for the GCN for each value of `n` in the specified range where n is used to generate a random graph of size n.

Each iteration of the loop does the following task:
1. Generate a deterministic random graph of size **n** by calling `generate_graph(n)`
2. Finds the standard target maximum independent set of G by calling `approx.maximum_independent_set(G)
3. Creates a new model based on the input parameters `input_dim`, `hidden_dim`, and `output_dim` by calling `GCN()`
4. Runs the training loop for `num_epochs` iterations
5. Display the results produced by GCN and time elapsed
6. Compares GCN results with target

